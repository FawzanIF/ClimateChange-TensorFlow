{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('daily-max-temperatures.csv', <http.client.HTTPMessage at 0x289a3249a00>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-max-temperatures.csv'\n",
    "urllib.request.urlretrieve(data_url, 'daily-max-temperatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_series(data, min, max):\n",
    "    data = data - min\n",
    "    data = data / max\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('daily-max-temperatures.csv', sep=',',\n",
    "                     infer_datetime_format=True, index_col='Date', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data sebanyak :  3650\n",
      "Data Train sebesar :  2920\n",
      "Data Test sebesar :  730\n"
     ]
    }
   ],
   "source": [
    "data = df.values\n",
    "data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
    "SPLIT_TIME = int(len(data) * 0.8)\n",
    "x_train = data[:SPLIT_TIME]\n",
    "x_valid = data[SPLIT_TIME:]\n",
    "print('Total Data sebanyak : ', df.size)\n",
    "print('Data Train sebesar : ', x_train.size)\n",
    "print('Data Test sebesar : ', x_valid.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 64\n",
    "batch_size = 256\n",
    "shuffle_buffer_size = 1000\n",
    "\n",
    "train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
    "valid_set = windowed_dataset(x_valid, window_size, batch_size, shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 10s 238ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 1.0000e-08\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 1.1220e-08\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 1.2589e-08\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 1.4125e-08\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 1.5849e-08\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 1.7783e-08\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 1.9953e-08\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 2.2387e-08\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 2.5119e-08\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 2.8184e-08\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 3.1623e-08\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 3.5481e-08\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 3.9811e-08\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 4.4668e-08\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 5.0119e-08\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 5.6234e-08\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2919 - lr: 6.3096e-08\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 7.0795e-08\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 7.9433e-08\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 8.9125e-08\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 1.0000e-07\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 1.1220e-07\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 1.2589e-07\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0528 - mae: 0.2940 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 1.4125e-07\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0528 - mae: 0.2939 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 1.5849e-07\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0528 - mae: 0.2939 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 1.7783e-07\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0528 - mae: 0.2939 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 1.9953e-07\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0527 - mae: 0.2939 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 2.2387e-07\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0527 - mae: 0.2939 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 2.5119e-07\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0527 - mae: 0.2939 - val_loss: 0.0520 - val_mae: 0.2918 - lr: 2.8184e-07\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0527 - mae: 0.2939 - val_loss: 0.0520 - val_mae: 0.2917 - lr: 3.1623e-07\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0527 - mae: 0.2939 - val_loss: 0.0520 - val_mae: 0.2917 - lr: 3.5481e-07\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0527 - mae: 0.2938 - val_loss: 0.0520 - val_mae: 0.2917 - lr: 3.9811e-07\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0527 - mae: 0.2938 - val_loss: 0.0520 - val_mae: 0.2917 - lr: 4.4668e-07\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0527 - mae: 0.2938 - val_loss: 0.0520 - val_mae: 0.2917 - lr: 5.0119e-07\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0527 - mae: 0.2938 - val_loss: 0.0520 - val_mae: 0.2916 - lr: 5.6234e-07\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0527 - mae: 0.2937 - val_loss: 0.0519 - val_mae: 0.2916 - lr: 6.3096e-07\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0527 - mae: 0.2937 - val_loss: 0.0519 - val_mae: 0.2916 - lr: 7.0795e-07\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0527 - mae: 0.2937 - val_loss: 0.0519 - val_mae: 0.2915 - lr: 7.9433e-07\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0527 - mae: 0.2936 - val_loss: 0.0519 - val_mae: 0.2915 - lr: 8.9125e-07\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0527 - mae: 0.2936 - val_loss: 0.0519 - val_mae: 0.2914 - lr: 1.0000e-06\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0526 - mae: 0.2935 - val_loss: 0.0519 - val_mae: 0.2914 - lr: 1.1220e-06\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0526 - mae: 0.2935 - val_loss: 0.0519 - val_mae: 0.2913 - lr: 1.2589e-06\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0526 - mae: 0.2934 - val_loss: 0.0518 - val_mae: 0.2912 - lr: 1.4125e-06\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0526 - mae: 0.2933 - val_loss: 0.0518 - val_mae: 0.2912 - lr: 1.5849e-06\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0526 - mae: 0.2933 - val_loss: 0.0518 - val_mae: 0.2911 - lr: 1.7783e-06\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0525 - mae: 0.2932 - val_loss: 0.0518 - val_mae: 0.2910 - lr: 1.9953e-06\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0525 - mae: 0.2931 - val_loss: 0.0517 - val_mae: 0.2908 - lr: 2.2387e-06\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0525 - mae: 0.2929 - val_loss: 0.0517 - val_mae: 0.2907 - lr: 2.5119e-06\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0524 - mae: 0.2928 - val_loss: 0.0516 - val_mae: 0.2906 - lr: 2.8184e-06\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0524 - mae: 0.2926 - val_loss: 0.0516 - val_mae: 0.2904 - lr: 3.1623e-06\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0523 - mae: 0.2925 - val_loss: 0.0515 - val_mae: 0.2902 - lr: 3.5481e-06\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0523 - mae: 0.2923 - val_loss: 0.0515 - val_mae: 0.2900 - lr: 3.9811e-06\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0522 - mae: 0.2920 - val_loss: 0.0514 - val_mae: 0.2897 - lr: 4.4668e-06\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0521 - mae: 0.2918 - val_loss: 0.0513 - val_mae: 0.2894 - lr: 5.0119e-06\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0520 - mae: 0.2915 - val_loss: 0.0512 - val_mae: 0.2891 - lr: 5.6234e-06\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0519 - mae: 0.2911 - val_loss: 0.0511 - val_mae: 0.2887 - lr: 6.3096e-06\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0518 - mae: 0.2907 - val_loss: 0.0510 - val_mae: 0.2883 - lr: 7.0795e-06\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0517 - mae: 0.2903 - val_loss: 0.0508 - val_mae: 0.2878 - lr: 7.9433e-06\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0515 - mae: 0.2897 - val_loss: 0.0507 - val_mae: 0.2872 - lr: 8.9125e-06\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0514 - mae: 0.2891 - val_loss: 0.0505 - val_mae: 0.2865 - lr: 1.0000e-05\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0512 - mae: 0.2884 - val_loss: 0.0503 - val_mae: 0.2858 - lr: 1.1220e-05\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0509 - mae: 0.2876 - val_loss: 0.0500 - val_mae: 0.2849 - lr: 1.2589e-05\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0507 - mae: 0.2867 - val_loss: 0.0497 - val_mae: 0.2839 - lr: 1.4125e-05\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0504 - mae: 0.2856 - val_loss: 0.0494 - val_mae: 0.2827 - lr: 1.5849e-05\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0500 - mae: 0.2844 - val_loss: 0.0491 - val_mae: 0.2814 - lr: 1.7783e-05\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0496 - mae: 0.2830 - val_loss: 0.0486 - val_mae: 0.2799 - lr: 1.9953e-05\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0492 - mae: 0.2814 - val_loss: 0.0482 - val_mae: 0.2782 - lr: 2.2387e-05\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0487 - mae: 0.2796 - val_loss: 0.0476 - val_mae: 0.2763 - lr: 2.5119e-05\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0481 - mae: 0.2775 - val_loss: 0.0470 - val_mae: 0.2741 - lr: 2.8184e-05\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0475 - mae: 0.2752 - val_loss: 0.0463 - val_mae: 0.2716 - lr: 3.1623e-05\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0467 - mae: 0.2726 - val_loss: 0.0456 - val_mae: 0.2689 - lr: 3.5481e-05\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0460 - mae: 0.2698 - val_loss: 0.0448 - val_mae: 0.2659 - lr: 3.9811e-05\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0451 - mae: 0.2666 - val_loss: 0.0439 - val_mae: 0.2625 - lr: 4.4668e-05\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0442 - mae: 0.2631 - val_loss: 0.0429 - val_mae: 0.2589 - lr: 5.0119e-05\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0431 - mae: 0.2593 - val_loss: 0.0419 - val_mae: 0.2549 - lr: 5.6234e-05\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0420 - mae: 0.2552 - val_loss: 0.0407 - val_mae: 0.2505 - lr: 6.3096e-05\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0409 - mae: 0.2506 - val_loss: 0.0395 - val_mae: 0.2458 - lr: 7.0795e-05\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0396 - mae: 0.2457 - val_loss: 0.0382 - val_mae: 0.2407 - lr: 7.9433e-05\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0383 - mae: 0.2405 - val_loss: 0.0369 - val_mae: 0.2352 - lr: 8.9125e-05\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0369 - mae: 0.2348 - val_loss: 0.0355 - val_mae: 0.2292 - lr: 1.0000e-04\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0355 - mae: 0.2286 - val_loss: 0.0340 - val_mae: 0.2228 - lr: 1.1220e-04\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0339 - mae: 0.2220 - val_loss: 0.0324 - val_mae: 0.2159 - lr: 1.2589e-04\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0323 - mae: 0.2148 - val_loss: 0.0308 - val_mae: 0.2084 - lr: 1.4125e-04\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0306 - mae: 0.2071 - val_loss: 0.0291 - val_mae: 0.2004 - lr: 1.5849e-04\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0289 - mae: 0.1989 - val_loss: 0.0274 - val_mae: 0.1918 - lr: 1.7783e-04\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0271 - mae: 0.1900 - val_loss: 0.0255 - val_mae: 0.1826 - lr: 1.9953e-04\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0253 - mae: 0.1806 - val_loss: 0.0237 - val_mae: 0.1730 - lr: 2.2387e-04\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0234 - mae: 0.1708 - val_loss: 0.0219 - val_mae: 0.1631 - lr: 2.5119e-04\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0216 - mae: 0.1608 - val_loss: 0.0200 - val_mae: 0.1531 - lr: 2.8184e-04\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0197 - mae: 0.1508 - val_loss: 0.0183 - val_mae: 0.1434 - lr: 3.1623e-04\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0180 - mae: 0.1412 - val_loss: 0.0166 - val_mae: 0.1344 - lr: 3.5481e-04\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0164 - mae: 0.1323 - val_loss: 0.0151 - val_mae: 0.1262 - lr: 3.9811e-04\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0149 - mae: 0.1243 - val_loss: 0.0137 - val_mae: 0.1188 - lr: 4.4668e-04\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0135 - mae: 0.1174 - val_loss: 0.0124 - val_mae: 0.1125 - lr: 5.0119e-04\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0123 - mae: 0.1119 - val_loss: 0.0114 - val_mae: 0.1077 - lr: 5.6234e-04\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0113 - mae: 0.1075 - val_loss: 0.0105 - val_mae: 0.1042 - lr: 6.3096e-04\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0106 - mae: 0.1043 - val_loss: 0.0099 - val_mae: 0.1017 - lr: 7.0795e-04\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0099 - mae: 0.1020 - val_loss: 0.0094 - val_mae: 0.1002 - lr: 7.9433e-04\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0095 - mae: 0.1007 - val_loss: 0.0090 - val_mae: 0.0995 - lr: 8.9125e-04\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0091 - mae: 0.1000 - val_loss: 0.0087 - val_mae: 0.0990 - lr: 0.0010\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0089 - mae: 0.0995 - val_loss: 0.0085 - val_mae: 0.0987 - lr: 0.0011\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0087 - mae: 0.0993 - val_loss: 0.0083 - val_mae: 0.0986 - lr: 0.0013\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0082 - val_mae: 0.0986 - lr: 0.0014\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0085 - mae: 0.0993 - val_loss: 0.0081 - val_mae: 0.0987 - lr: 0.0016\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0084 - mae: 0.0992 - val_loss: 0.0081 - val_mae: 0.0985 - lr: 0.0018\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0083 - mae: 0.0989 - val_loss: 0.0080 - val_mae: 0.0982 - lr: 0.0020\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0083 - mae: 0.0988 - val_loss: 0.0079 - val_mae: 0.0981 - lr: 0.0022\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0082 - mae: 0.0986 - val_loss: 0.0079 - val_mae: 0.0976 - lr: 0.0025\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0081 - mae: 0.0981 - val_loss: 0.0078 - val_mae: 0.0971 - lr: 0.0028\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0081 - mae: 0.0978 - val_loss: 0.0077 - val_mae: 0.0968 - lr: 0.0032\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0080 - mae: 0.0974 - val_loss: 0.0076 - val_mae: 0.0962 - lr: 0.0035\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0079 - mae: 0.0969 - val_loss: 0.0076 - val_mae: 0.0955 - lr: 0.0040\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0078 - mae: 0.0963 - val_loss: 0.0075 - val_mae: 0.0949 - lr: 0.0045\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0077 - mae: 0.0958 - val_loss: 0.0073 - val_mae: 0.0944 - lr: 0.0050\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0076 - mae: 0.0949 - val_loss: 0.0072 - val_mae: 0.0932 - lr: 0.0056\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0075 - mae: 0.0944 - val_loss: 0.0071 - val_mae: 0.0925 - lr: 0.0063\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0074 - mae: 0.0934 - val_loss: 0.0069 - val_mae: 0.0911 - lr: 0.0071\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0072 - mae: 0.0923 - val_loss: 0.0068 - val_mae: 0.0903 - lr: 0.0079\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0071 - mae: 0.0916 - val_loss: 0.0066 - val_mae: 0.0884 - lr: 0.0089\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0069 - mae: 0.0901 - val_loss: 0.0063 - val_mae: 0.0870 - lr: 0.0100\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0067 - mae: 0.0885 - val_loss: 0.0061 - val_mae: 0.0851 - lr: 0.0112\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0065 - mae: 0.0868 - val_loss: 0.0058 - val_mae: 0.0826 - lr: 0.0126\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0061 - mae: 0.0838 - val_loss: 0.0052 - val_mae: 0.0750 - lr: 0.0141\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0055 - mae: 0.0793 - val_loss: 0.0047 - val_mae: 0.0734 - lr: 0.0158\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0052 - mae: 0.0773 - val_loss: 0.0045 - val_mae: 0.0721 - lr: 0.0178\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0050 - mae: 0.0757 - val_loss: 0.0042 - val_mae: 0.0694 - lr: 0.0200\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0048 - mae: 0.0744 - val_loss: 0.0041 - val_mae: 0.0681 - lr: 0.0224\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0047 - mae: 0.0737 - val_loss: 0.0040 - val_mae: 0.0680 - lr: 0.0251\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0046 - mae: 0.0736 - val_loss: 0.0039 - val_mae: 0.0677 - lr: 0.0282\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0046 - mae: 0.0735 - val_loss: 0.0039 - val_mae: 0.0677 - lr: 0.0316\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0046 - mae: 0.0736 - val_loss: 0.0039 - val_mae: 0.0677 - lr: 0.0355\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0046 - mae: 0.0735 - val_loss: 0.0039 - val_mae: 0.0675 - lr: 0.0398\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0045 - mae: 0.0735 - val_loss: 0.0039 - val_mae: 0.0673 - lr: 0.0447\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0045 - mae: 0.0733 - val_loss: 0.0038 - val_mae: 0.0672 - lr: 0.0501\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0045 - mae: 0.0732 - val_loss: 0.0038 - val_mae: 0.0671 - lr: 0.0562\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0045 - mae: 0.0730 - val_loss: 0.0038 - val_mae: 0.0670 - lr: 0.0631\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0045 - mae: 0.0729 - val_loss: 0.0038 - val_mae: 0.0669 - lr: 0.0708\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0044 - mae: 0.0727 - val_loss: 0.0038 - val_mae: 0.0666 - lr: 0.0794\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0044 - mae: 0.0725 - val_loss: 0.0037 - val_mae: 0.0663 - lr: 0.0891\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0044 - mae: 0.0723 - val_loss: 0.0037 - val_mae: 0.0659 - lr: 0.1000\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0044 - mae: 0.0721 - val_loss: 0.0037 - val_mae: 0.0661 - lr: 0.1122\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0043 - mae: 0.0719 - val_loss: 0.0037 - val_mae: 0.0658 - lr: 0.1259\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0043 - mae: 0.0716 - val_loss: 0.0036 - val_mae: 0.0653 - lr: 0.1413\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0043 - mae: 0.0714 - val_loss: 0.0036 - val_mae: 0.0654 - lr: 0.1585\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0043 - mae: 0.0710 - val_loss: 0.0036 - val_mae: 0.0646 - lr: 0.1778\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0042 - mae: 0.0707 - val_loss: 0.0035 - val_mae: 0.0645 - lr: 0.1995\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.0046 - mae: 0.0747 - val_loss: 0.0036 - val_mae: 0.0680 - lr: 0.2239\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0056 - mae: 0.0825 - val_loss: 0.0057 - val_mae: 0.0925 - lr: 0.2512\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0048 - mae: 0.0756 - val_loss: 0.0037 - val_mae: 0.0692 - lr: 0.2818\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
    "                            strides=1, padding=\"causal\",\n",
    "                            activation=\"relu\",\n",
    "                            input_shape=[None, 1]),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "        tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "            lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "                    optimizer=optimizer,\n",
    "                    metrics=[\"mae\"])\n",
    "history = model.fit(train_set, epochs=150, callbacks=[lr_schedule], validation_data=valid_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a9bd0bc7b15453bb15ec2d775732272e1be6fd4da0fc6dc9034c80391f97b78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
